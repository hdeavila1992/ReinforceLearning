# C贸digos de Aprendizaje por Refuerzo

Este repositorio contiene implementaciones y ejemplos de algoritmos de aprendizaje por refuerzo (Reinforcement Learning) desarrollados con fines educativos y de investigaci贸n.

##  Contenido del Repositorio

### 1. FrozenLake Q-Learning (`FrozenLake5.py`)
Implementaci贸n del algoritmo Q-Learning aplicado al ambiente FrozenLake de OpenAI Gym.

**Caracter铆sticas:**
- Algoritmo Q-Learning con exploraci贸n 蔚-greedy decreciente
- Ambiente FrozenLake-v1 con penalizaciones personalizadas
- Visualizaci贸n de la pol铆tica aprendida
- Configuraci贸n de hiperpar谩metros: learning rate = 0.1, 纬 = 0.95

**Funcionalidades principales:**
- Entrenamiento del agente durante 500 episodios
- Penalizaciones adicionales en estados espec铆ficos (5, 7, 11, 12)
- Funci贸n de visualizaci贸n para observar la pol铆tica aprendida

### 2. Q-Iteration para Robot Limpiador (`Q_iteration_Robot_clening.ipynb`)
Implementaci贸n del algoritmo Q-Iteration (Value Iteration) para un problema de robot limpiador en un ambiente determin铆stico.

**Caracter铆sticas del ambiente:**
- 6 estados discretos
- 2 acciones posibles: [-1, 1] (moverse izquierda/derecha)
- Estados terminales con recompensas espec铆ficas
- Ambiente completamente determin铆stico

**Componentes principales:**
- Clase `enviroment()`: Define las din谩micas del ambiente del robot
- Clase `Qiteration()`: Implementa el algoritmo de iteraci贸n Q
- Funci贸n de recompensa personalizada
- Visualizaci贸n de la convergencia de la funci贸n Q

### 3. FrozenLake Colaborativo (`FrozenLake2024.ipynb`)
Implementaci贸n colaborativa del ambiente FrozenLake con extensiones adicionales.

##  Instalaci贸n y Uso

### Requisitos
```bash
pip install numpy
pip install gym
pip install matplotlib
```

### Ejecuci贸n

**Para FrozenLake Q-Learning:**
```bash
python FrozenLake5.py
```

**Para Q-Iteration Robot:**
```bash
jupyter notebook Q_iteration_Robot_clening.ipynb
```

##  Algoritmos Implementados

### Q-Learning
- **Tipo:** Model-free, off-policy
- **Aplicaci贸n:** Ambiente estoc谩stico (FrozenLake)
- **Exploraci贸n:** 蔚-greedy decreciente

### Q-Iteration (Value Iteration)
- **Tipo:** Model-based, planning
- **Aplicaci贸n:** Ambiente determin铆stico (Robot limpiador)
- **Convergencia:** Garantizada para ambientes determin铆sticos

##  Objetivos de Aprendizaje

Este repositorio est谩 dise帽ado para:
- Comprender las diferencias entre algoritmos model-free y model-based
- Implementar algoritmos de aprendizaje por refuerzo desde cero
- Comparar el comportamiento en ambientes determin铆sticos vs estoc谩sticos
- Visualizar el proceso de aprendizaje y convergencia

##  Resultados

Los algoritmos implementados demuestran:
- Convergencia exitosa hacia pol铆ticas 贸ptimas
- Manejo efectivo de la exploraci贸n vs explotaci贸n
- Adaptaci贸n a diferentes tipos de ambientes

##  Personalizaci贸n

Los c贸digos incluyen par谩metros configurables:
- **Learning rate:** Controla la velocidad de aprendizaje
- **Discount factor (纬):** Importancia de recompensas futuras
- **N煤mero de episodios:** Duraci贸n del entrenamiento
- **Funciones de recompensa:** Modificables seg煤n el problema

##  Referencias

- Sutton, R. S., & Barto, A. G. (2018). Reinforcement learning: An introduction.
- OpenAI Gym: https://gym.openai.com/
- Documentaci贸n de NumPy y Matplotlib

##  Contribuciones

Este repositorio est谩 abierto a contribuciones para:
- Nuevos algoritmos de RL
- Mejoras en la documentaci贸n
- Optimizaciones de c贸digo
- Nuevos ambientes de prueba

---

**Nota:** Este repositorio tiene fines educativos y de investigaci贸n en el 谩rea de aprendizaje por refuerzo.
